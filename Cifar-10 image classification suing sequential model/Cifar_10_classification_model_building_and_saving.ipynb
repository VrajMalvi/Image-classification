{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar-10_classification_model_building_and_saving.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **The CIFAR-10 dataset**\n",
        "\n",
        "### The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "### The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. \n",
        "\n",
        "### Here are the classes in the dataset:\n",
        "\n",
        "* airplane\n",
        "\n",
        "* automobile\n",
        "\n",
        "* bird\n",
        "\n",
        "* cat\n",
        " \n",
        "* deer\n",
        "\n",
        "* dog \n",
        "\n",
        "* frog\n",
        "\n",
        "* horse\n",
        "\n",
        "* ship\n",
        "\n",
        "* truck\n",
        "\n"
      ],
      "metadata": {
        "id": "lSra0R-2FD7Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "py82b0jtF-MF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and test dataset\n",
        "\n",
        "def load_dataset():\n",
        "  (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\n",
        "# reshape dataset to have single channel\n",
        "  # shape[0] will give no of data , image width and hight , color perameter gray = 1, rgb 3\n",
        "  # trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "  # testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\n",
        "  print(\"Shape of training data:\")\n",
        "  print(trainX.shape)\n",
        "  print(trainY.shape)\n",
        "  print(\"Shape of test data:\")\n",
        "  print(testX.shape)\n",
        "  print(testY.shape)\n",
        "\n",
        "  # One hot encode target values since problem is multi class(with int 0 to 9), so instead of [0 1 2 3] it will be [1 0 0] for 1, [010] for 2\n",
        "\n",
        "  trainY = to_categorical(trainY)\n",
        "  testY = to_categorical(testY)\n",
        "\n",
        "  return trainX, trainY, testX, testY"
      ],
      "metadata": {
        "id": "aKpo14ImIInO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale Pixels \n",
        "def prep_pixels(train,test):\n",
        "\n",
        "# convert from integers to floats\n",
        "  train_norm = train.astype('float32')\n",
        "  test_norm= test.astype('float32')\n",
        "\n",
        "# normalize to range 0-1 \n",
        "  train_norm = train_norm / 255.0   # divided by 255 as it was max range for gray scale\n",
        "  test_norm = test_norm / 255.0\n",
        "\n",
        "# return normalized range\n",
        "  return train_norm, test_norm"
      ],
      "metadata": {
        "id": "M58kexnWGBXn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define CNN model\n",
        "def define_model():\n",
        "  \n",
        "  model = Sequential()\n",
        "  \n",
        "  # HIDDEN LAYER 1  \n",
        "  model.add(Conv2D(32, (3,3), activation='relu',padding='same', kernel_initializer='he_uniform', input_shape=(32,32,3)))\n",
        "  model.add(Conv2D(32, (3,3), activation='relu',padding='same', kernel_initializer='he_uniform'))\n",
        "  model.add(MaxPooling2D((2,2)))  # stride will be 2 as we didnt define it it will take default null which is same as pool size\n",
        "\n",
        "  # HIDDEN LAYER 2\n",
        "  model.add(Conv2D(64, (3,3), activation='relu',padding='same', kernel_initializer='he_uniform'))\n",
        "  model.add(Conv2D(64, (3,3), activation='relu',padding='same', kernel_initializer='he_uniform'))\n",
        "  model.add(MaxPooling2D((2,2)))  # stride will be 2 as we didnt define it it will take default null which is same as pool size\n",
        "\n",
        "  # HIDDEN LAYER 3\n",
        "  model.add(Conv2D(128, (3,3), activation='relu',padding='same', kernel_initializer='he_uniform'))\n",
        "  model.add(Conv2D(128, (3,3), activation='relu',padding='same', kernel_initializer='he_uniform'))\n",
        "  model.add(MaxPooling2D((2,2)))  # stride will be 2 as we didnt define it it will take default null which is same as pool size\n",
        "\n",
        "  # flatten node before giving to NN\n",
        "  model.add(Flatten())\n",
        "\n",
        "\n",
        "  model.add(Dense(128 , activation='relu', kernel_initializer='he_uniform'))  # 128 node\n",
        "  model.add(Dense(10, activation='softmax')) # 10 node in output as we have 10 classes\n",
        "\n",
        "# Compile model\n",
        "\n",
        "  # Stocastic gradient descent\n",
        "  opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
        "  # we are dealing with multiclass classification so we use categorical_crossentropy as loss function\n",
        "  \n",
        "  model.summary()\n",
        "  plot_model(model, to_file = 'CNN_seq.png')\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "yOnzkMgVGBVA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# fit model\n",
        "\tmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=2)\n",
        "\t# save model to use in other files\n",
        "\tmodel.save('final_model.h5')\n"
      ],
      "metadata": {
        "id": "0em2NiC2GBS9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7-GNOoTGBQ3",
        "outputId": "3f507c0e-afec-448e-fb40-1f493bf26868"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "Shape of training data:\n",
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "Shape of test data:\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 550,570\n",
            "Trainable params: 550,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1563/1563 - 367s - loss: 1.6028 - accuracy: 0.4182 - 367s/epoch - 235ms/step\n",
            "Epoch 2/10\n",
            "1563/1563 - 367s - loss: 1.2382 - accuracy: 0.5603 - 367s/epoch - 235ms/step\n",
            "Epoch 3/10\n",
            "1563/1563 - 371s - loss: 1.0456 - accuracy: 0.6310 - 371s/epoch - 238ms/step\n",
            "Epoch 4/10\n",
            "1563/1563 - 374s - loss: 0.9090 - accuracy: 0.6809 - 374s/epoch - 239ms/step\n",
            "Epoch 5/10\n",
            "1563/1563 - 368s - loss: 0.8052 - accuracy: 0.7180 - 368s/epoch - 236ms/step\n",
            "Epoch 6/10\n",
            "1563/1563 - 367s - loss: 0.7159 - accuracy: 0.7513 - 367s/epoch - 235ms/step\n",
            "Epoch 7/10\n",
            "1563/1563 - 368s - loss: 0.6382 - accuracy: 0.7763 - 368s/epoch - 235ms/step\n",
            "Epoch 8/10\n",
            "1563/1563 - 367s - loss: 0.5692 - accuracy: 0.8009 - 367s/epoch - 235ms/step\n",
            "Epoch 9/10\n",
            "1563/1563 - 367s - loss: 0.5083 - accuracy: 0.8232 - 367s/epoch - 235ms/step\n",
            "Epoch 10/10\n",
            "1563/1563 - 367s - loss: 0.4446 - accuracy: 0.8452 - 367s/epoch - 235ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iAwLSkKbGBOO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}