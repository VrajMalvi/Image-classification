# -*- coding: utf-8 -*-
"""Image classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z42Rcz4TiGt3qcA483ZlaEQCCGIcNTVm

## Fashion MNIST

this data set is directly available on tensorflow adn keras library, so that we can import this data set from libraries without downloading.

(clothing Images)


*  it is consist of 60K example for training and 10K examples for test data. Each example is a 28 x 28 grayscale Image, associated woth lable form 10 class.

T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot (starting 0 to 9)
"""

from tensorflow.keras import layers
from keras.datasets import fashion_mnist
from tensorflow.keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from tensorflow.keras.optimizers import SGD
from numpy import mean
from numpy import std
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
from tensorflow.keras.utils import plot_model

# Load train and test dataset

def load_dataset():
  (trainX, trainY), (testX, testY) = fashion_mnist.load_data()

# reshape dataset to have single channel
  # shape[0] will give no of data which is 60K we know, image width and hight = 28, color perameter gray = 1
  trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))
  testX = testX.reshape((testX.shape[0], 28, 28, 1))

# One hot encode target values since problem is multi class(with int 0 to 9), so instead of [0 1 2 3] it will be [1 0 0] for 1, [010] for 2

  trainY = to_categorical(trainY)
  testY = to_categorical(testY)

  return trainX, trainY, testX, testY

"""pixel values for image dataset are unsigned int range of 0 to 255 (for gray scale)"""

# Scale Pixels 
def prep_pixels(train,test):

# convert from integers to floats
  train_norm = train.astype('float32')
  test_norm= test.astype('float32')

# normalize to range 0-1 
  train_norm = train_norm / 255.0   # divided by 255 as it was max range for gray scale
  test_norm = test_norm / 255.0

# return normalized range
  return train_norm, test_norm

# define CNN model
def define_model():
  
  model = Sequential()
  model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', input_shape=(28,28,1)))
  model.add(MaxPooling2D((2,2)))  # stride will be 2 as we didnt define it it will take default null which is same as pool size
  model.add(Flatten())
  model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))  # 100 node
  model.add(Dense(10, activation='softmax')) # 10 node in output as we have 10 classes

# Compile model

  # Stocastic gradient descent
  opt = SGD(learning_rate=0.01, momentum=0.9)
  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) 
  # we are dealing with multiclass classification so we use categorical_crossentropy as loss function
  
  model.summary()
  plot_model(model, to_file = 'CNN_seq.png')
  
  return model

# run the test harness for evaluating a model
def run_test_harness():
	# load dataset
	trainX, trainY, testX, testY = load_dataset()
	# prepare pixel data
	trainX, testX = prep_pixels(trainX, testX)
	# define model
	model = define_model()
	# fit model
	model.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)
	# save model
	#model.save('final_model.h5')

# entry point, run the test harness
run_test_harness()