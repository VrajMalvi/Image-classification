{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Fashion MNIST\n",
        "\n",
        "this data set is directly available on tensorflow adn keras library, so that we can import this data set from libraries without downloading.\n",
        "\n",
        "(clothing Images)\n",
        "\n",
        "\n",
        "*  it is consist of 60K example for training and 10K examples for test data. Each example is a 28 x 28 grayscale Image, associated woth lable form 10 class.\n",
        "\n",
        "T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot (starting 0 to 9)\n"
      ],
      "metadata": {
        "id": "KRn66ExqTwUm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_XKAz6eQ5tZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and test dataset\n",
        "\n",
        "def load_dataset():\n",
        "  (trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "\n",
        "# reshape dataset to have single channel\n",
        "  # shape[0] will give no of data which is 60K we know, image width and hight = 28, color perameter gray = 1\n",
        "  trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "  testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\n",
        "# One hot encode target values since problem is multi class(with int 0 to 9), so instead of [0 1 2 3] it will be [1 0 0] for 1, [010] for 2\n",
        "\n",
        "  trainY = to_categorical(trainY)\n",
        "  testY = to_categorical(testY)\n",
        "\n",
        "  return trainX, trainY, testX, testY"
      ],
      "metadata": {
        "id": "8iVFRPMba42t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pixel values for image dataset are unsigned int range of 0 to 255 (for gray scale)"
      ],
      "metadata": {
        "id": "nH0dpp6dfVLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale Pixels \n",
        "def prep_pixels(train,test):\n",
        "\n",
        "# convert from integers to floats\n",
        "  train_norm = train.astype('float32')\n",
        "  test_norm= test.astype('float32')\n",
        "\n",
        "# normalize to range 0-1 \n",
        "  train_norm = train_norm / 255.0   # divided by 255 as it was max range for gray scale\n",
        "  test_norm = test_norm / 255.0\n",
        "\n",
        "# return normalized range\n",
        "  return train_norm, test_norm"
      ],
      "metadata": {
        "id": "ntepBjDtc43c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define CNN model\n",
        "def define_model():\n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', input_shape=(28,28,1)))\n",
        "  model.add(MaxPooling2D((2,2)))  # stride will be 2 as we didnt define it it will take default null which is same as pool size\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))  # 100 node\n",
        "  model.add(Dense(10, activation='softmax')) # 10 node in output as we have 10 classes\n",
        "\n",
        "# Compile model\n",
        "\n",
        "  # Stocastic gradient descent\n",
        "  opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
        "  # we are dealing with multiclass classification so we use categorical_crossentropy as loss function\n",
        "  \n",
        "  model.summary()\n",
        "  plot_model(model, to_file = 'CNN_seq.png')\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "Ee5nlBIuhG1j"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# fit model\n",
        "\tmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\n",
        "\t# save model\n",
        "\t#model.save('final_model.h5')\n"
      ],
      "metadata": {
        "id": "hRCYJQcRkZUj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTA6I14mly_q",
        "outputId": "1c7c90b9-3710-43fa-a6d8-ca50b9d16797"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 5408)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 100)               540900    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 542,230\n",
            "Trainable params: 542,230\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}